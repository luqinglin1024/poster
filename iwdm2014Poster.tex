\documentclass[25pt, a0paper, portrait, margin=0mm, innermargin=15mm, blockverticalspace=10mm, colspace=10mm, subcolspace=8mm]{tikzposter}

\usepackage{amsmath}
\usepackage{epsf,graphicx,subfig}
\setcounter{tocdepth}{3}
\usepackage{xcolor}
\usepackage{lineno}
\usepackage[nolist]{acronym}
\usepackage{amssymb,amsmath}
\usepackage{standalone}
\usepackage{tikz}
\usepackage{pgfplots,pgfplotstable}
\usepackage{scalefnt}
\usetikzlibrary{positioning}
\usetikzlibrary{pgfplots.groupplots}

\input{includePgfplotsWorkaround.tex}

\definecolor{udgColor}{RGB}{82,119,213}

\title{\acs{sift} texture description for understanding breast ultrasound images}
\author{Joan Massich, Fabrice Meriaudeau, Melcior Sent{\'i}s, Sergi Ganau, Elsa~P{\'e}rez, Domenec Puig, Robert  Mart{\'i}, Arnau Oliver and Joan Mart{\'i}}

%\institute{contact author: sik@eia.udg.edu}
\usetheme{Autumn}\usecolorstyle[colorPalette=BrownBlueOrange]{Germany}
%\usetheme{Simple} \usecolorstyle[colorOne=udgColor]{Denmark} 

\input{defineBreastGTlabelColors.tex}

\begin{document}\maketitle
\input{acronyms.tex}
\acresetall

\graphicspath{{figures/paperFigures/}}


\begin{columns} 
  \column{0.6}
\block{Abstract}{
Texture is a powerful cue for describing structures that show a high degree of similarity in their image intensity patterns. 
This paper describes the use of \acf{sift}, both as low-level and high-level descriptors, applied to differentiate the tissues present in breast US images. 

For such a task, a subset of 16 images has been randomly selected from a larger dataset of 700 \ac{us} images acquired at the \emph{UDIAT Diagnostic Centre of Parc Taul\'{i}} in Sabadell (Catalunya), between 2010 and 2012.
This subset has been complemented with multi-label \ac{gt}, as illustrated in figure~\ref{fig:dataExample}.

Experimental results are provided showing the validity of the proposed approach for describing the tissues in breast US images.

}
  \column{0.4}
\block{}{
\begin{tikzfigure}[Dataset sample. From left to right: image sample, accompanying multi-label \ac{gt}, tissue label \ac{gt} color-coding.]
  \centering
  \input{./figures/gtExample/gtExample.tex}
  \label{fig:dataExample}
\end{tikzfigure}
}
\end{columns}
%\begin{keywords}
%breast cancer, ultrasound, texture, SIFT
%\end{keywords}

\block{\ac{sift} as a low-level descriptor, tested using \ac{map}}{
  In this experiment, it has been analyzed how separable are the tissue classes present in breast ultrasound images, when using low-level descriptors based on \ac{sift} to encode \ac{us} texture.
  Here a Bayesian framework has been assumed to perform the tissue discrimination and its results are presented both qualitatively (see fig.~\ref{fig:model}-\ref{fig:MAP}) and quantitatively (see fig.~\ref{fig:llConfMatrix}).
  
  All the pixel positions of all the images are used as a key-point for extracting a \ac{sift} descriptor and mapped in the $128D$ feature space of \ac{sift}.
  This \ac{sift} space is then projected into a $2D$ space to visually assess how the tissue classes are distributed in such space.
  From this projected space, models (see fig.~\ref{fig:model}) and priors (see fig.~\ref{fig:prior}) are extracted to infer the \ac{map} probability.
  Figure~\ref{fig:MAP} shows this \ac{map} probability illustrating how the tissue classes are separated based on the observed data.

In order to generate cross-validated quantitative results, the descriptors have been randomly sampled as follows: ($10.000\text{ samples} \times 10 \text{ classes}) \times 5 \text{ folds}$.
 At each round 4 folds have been used for training the %\ac{ml} term in eq.\,\ref{eq:bayes} ($P(\bar{x}_a|\omega)$) 
 models 
 and the remaining fold has been used for testing.
 Figure~\ref{fig:llConfMatrix} shows the corss-validated confusion matrix resulting from classifying breast tissues based on a Bayesian framework using either low-level \ac{sift} texture descriptors or intensity.
The trance of the confusion matrix corresponds to the sensitivity which provides a general sense of performance across all the labels.
The \ac{tpr} value obtained for the intensity case is $16.6\pm27.5\%$, whereas for the \ac{sift} case is $18.8\pm17.2\%$ which show that both feature spaces produce similar results.
}

\begin{columns} 

\column{0.34} \block{}{
\begin{tikzfigure}[Distribution of the \acs{sift} descriptors for some classes in the \ac{gt}.]
\input{./figures/lowLevelModelProbability/lowLevelModelProbability.tex}
  \label{fig:model}
\end{tikzfigure}
}

\column{0.14} \block{}{
\begin{tikzfigure}[Data prior knowlage.] %Class tiussue and feature priors.]
  \input{./figures/lowLevelPrior/lowLevelPrior.tex}
  \label{fig:prior}
\end{tikzfigure}
} 

\column{0.17} \block{}{
\begin{tikzfigure}[ Qualitative evaluation of the \ac{map} labeling of the feature space.]
\input{./figures/lowLevelMAP/lowLevelMAP.tex}
  \label{fig:MAP}
\end{tikzfigure}
}

\column{0.35} \block{}{
\begin{tikzfigure}[some caption]
\input{./figures/lowLevelConfMatrix/lowLevelConfusionMatrix.tex}
  \label{fig:llConfMatrix}
\end{tikzfigure}
} 

\end{columns}

\block{\ac{sift} as a high-level descriptor using \acf{bof}, tested using \ac{rbf}-\ac{svm} classifier}{
  Texture is an area property related to spatial repetition of structures, statistical similarities, or both.
  In this experiment superpixels are extracted using \ac{qs} methodology to generate this areas. Some of this superpixels are illustrated in figure~\ref{fig:bof}.
  For each superpixel, a high-level texture descriptor is build as a \ac{bof} of \ac{sift} descriptors. 
  Initially the \ac{sift} space is clustered to generate a codebook. Here k-means procedure with $k=36$ is used to generate these codebooks. 
  Figure~\ref{fig:bof} shows an arbitrary coloring of each cluster to illustrate how the codebook produce a hard quantification of the \ac{sift} space.
  Finally the \ac{bof} descriptor for a superpixel corresponds to the occurrence study of the codebook using the \ac{sift} descriptors belonging to this particular superpixel (see 1-8 in fig\,\ref{fig:bof}). 

  In order to produce quantitative results, dataset of superpixels is generated based on the images and the multi-label \ac{gt} available.
  For a superpixel to be eligible, an area larger than $75\%$ need to belong to a single \ac{gt} label. The resulting dataset contains 20 folds of 8 superpixels (one per class). 

  The experiment has been repeated for different coodebooks to take into account the variability of the coodebook within the results. 
  Figure~\ref{fig:hlConfMatrix} compares the results of using \ac{bof} based on \ac{sift} or intensity for encoding \ac{us} texture. 
  The sensitivity achieved is $29\pm3.6\%$ for the intenisty and $33.5\pm2.3\%$ for \ac{sift}.
}

\begin{columns}
\column{0.60} \block{}{
\begin{tikzfigure}[ \acs{sift}-\acs{bof} descriptors qualitative analysis. (Left) image example. (Right) Dictionary representation colored using the location of the keypoint location in fig.\,\ref{fig:siftMapping}a space. (1-8) Occurrence of the dictionary's key-points associated to each region highlighted in the original image.]
\input{./figures/backOfFeatures/backOfFeatures.tex} 
\label{fig:bof}
\end{tikzfigure}
}
\column{0.40} \block{}{
\begin{tikzfigure}[some caption]
\input{./figures/lowLevelConfMatrix/lowLevelConfusionMatrix.tex}
\label{fig:hlConfMatrix}
\end{tikzfigure}
} 
\end{columns}


%\block[titleoffsety=-1cm,bodyoffsety=-1cm]{Sample document}{This poster...}
\block{Conclusion}{
The present study was designed to explore the usage of \ac{sift} feature space as a texture for characterizing the different tissues present in a breast \ac{us} image. 
The usage of \ac{sift} either as a low-level or high-level texture descriptor has been evaluated in comparison to intensity features, which are the features most commonly used.
The fact that \ac{sift} and intensity descriptors produce similar results, encourages further studies on using \ac{sift} texture descriptors characterizing breast tissues in \ac{us} images.

}
%\note[targetoffsetx=24cm, targetoffsety=-9cm,radius=8cm,width=.75\textwidth,innersep=.4cm]{You can...}
\note[targetoffsetx=0cm,targetoffsety=-9cm,radius=8cm,width=.5\textwidth,innersep=.4cm]{This work was partially supported by the Spanish Science and Innovation grant nb.\,TIN2012-37171-C02-01 and TTIN2012-37171-C02-02, and the Regional Council of
Burgundy.}
\end{document}
